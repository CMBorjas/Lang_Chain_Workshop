{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c969e783",
   "metadata": {},
   "source": [
    "# LangChain Workshop: Building Intelligent Applications with Local LLMs\n",
    "\n",
    "Welcome to the **LangChain Workshop** — an interactive session designed to introduce you to one of the most powerful frameworks for building **AI-driven applications**.  \n",
    "In this workshop, you’ll learn how to connect **Large Language Models (LLMs)** with your own data, enabling intelligent systems that can **reason, retrieve, and respond** using real-world information.\n",
    "\n",
    "---\n",
    "\n",
    "## What is LangChain?\n",
    "\n",
    "**LangChain** is an open-source framework that simplifies working with LLMs like GPT or LLaMA by giving them **memory**, **tools**, and **data access**.  \n",
    "Instead of just chatting with a model, LangChain helps you **build agents and applications** that can:\n",
    "- Read and summarize documents  \n",
    "- Answer questions from your own data  \n",
    "- Chain multiple reasoning steps together  \n",
    "- Connect to APIs, databases, and local files  \n",
    "\n",
    "Think of LangChain as the “glue” between your AI model and the information or actions it needs to perform.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Learn LangChain?\n",
    "\n",
    "Learning LangChain unlocks your ability to **build real-world AI tools** that go beyond simple prompts.  \n",
    "By the end of this workshop, you’ll understand how to:\n",
    "\n",
    "- Create **Retrieval-Augmented Generation (RAG)** pipelines  \n",
    "- Store and search data in **vector databases** (like Chroma or Qdrant)  \n",
    "- Integrate **local LLMs** (e.g., Ollama + Llama 3)  \n",
    "- Run your own **AI-powered assistant** on your computer or server  \n",
    "\n",
    "LangChain bridges the gap between **AI theory and practical engineering**, giving you hands-on experience with the same technologies powering next-generation AI products.\n",
    "\n",
    "---\n",
    "\n",
    "## What You’ll Build\n",
    "\n",
    "In this session, you’ll:\n",
    "1. Set up a local LangChain environment  \n",
    "2. Ingest and index your own text data  \n",
    "3. Create a simple **local research assistant** that can answer questions about your documents  \n",
    "4. Run it fully **offline** using a local LLM  \n",
    "\n",
    "By the end, you’ll have a working foundation for your own **AI apps, research tools, and automation projects**.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic familiarity with **Python**  \n",
    "- Installed **Jupyter Notebook**    \n",
    "\n",
    "---\n",
    "\n",
    "## Let’s Begin\n",
    "\n",
    "> “LangChain turns your data into dialogue and your ideas into intelligent systems.”  \n",
    "Let’s dive in and explore how you can build your own AI assistant — from scratch to smart — in one workshop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc344330",
   "metadata": {},
   "source": [
    "# 1: Cell imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae587a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: c:\\Users\\cmand\\Lang_Chain_workshop\\Lang_Chain_Workshop\\env\\Scripts\\python.exe\n",
      "cryptography: 46.0.3\n",
      "pypdf: 6.1.3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "import hashlib\n",
    "import cryptography\n",
    "import pypdf\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredURLLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings, ChatOllama\n",
    "from pypdf.errors import WrongPasswordError\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"cryptography:\", cryptography.__version__)\n",
    "print(\"pypdf:\", pypdf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169576d",
   "metadata": {},
   "source": [
    "# 2: Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3072ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: C:\\Users\\cmand\\Lang_Chain_workshop\\Lang_Chain_Workshop\n",
      "DATA_DIR: C:\\Users\\cmand\\Lang_Chain_workshop\\Lang_Chain_Workshop\\data\n",
      "DB_DIR: C:\\Users\\cmand\\Lang_Chain_workshop\\Lang_Chain_Workshop\\chroma_db\n",
      "DATA_DIR contents: ['CalculusVolume1-OP.pdf']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ROOT_DIR = Path(__file__).parent.resolve()\n",
    "except NameError:\n",
    "    ROOT_DIR = Path(os.getcwd()).resolve()\n",
    "\n",
    "if ROOT_DIR.name.lower() == \"notebooks\":\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "DB_DIR   = ROOT_DIR / \"chroma_db\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT_DIR:\", ROOT_DIR)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DB_DIR:\", DB_DIR)\n",
    "print(\"DATA_DIR contents:\", [p.name for p in DATA_DIR.glob('*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d62a2a",
   "metadata": {},
   "source": [
    "# 3: Ollama Models\n",
    "- Requirements:\n",
    "    - Model: 3.2:1b\n",
    "    - \n",
    "    - ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5315fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL   = \"llama3.2:1b\"          # ollama pull llama3.1\n",
    "EMBED_MODEL = \"nomic-embed-text\"  # ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a10172",
   "metadata": {},
   "source": [
    "### 3a: Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6677d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: C:\\Users\\cmand\\Lang_Chain_workshop\\Lang_Chain_Workshop\\data\n",
      "DB_DIR: C:\\Users\\cmand\\Lang_Chain_workshop\\Lang_Chain_Workshop\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DB_DIR:\", DB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c8325",
   "metadata": {},
   "source": [
    "# 4: Sanity Check\n",
    "- This will error if Ollama isn't running or the model isn't pulled yet.\n",
    "- In a terminal (outside Python), run:\n",
    "    - ollama pull llama3.2:1b\n",
    "    - ollama pull nomic-embed-text\n",
    "- Forces Chroma to use the ROOT DB_DIR (outside notebooks) <- hard pins the path\n",
    "- We use client, to point to our database.\n",
    "- Sanity check: confirm the DB file is in the right folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5753b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM and Embeddings ready\n",
      "DB present at: C:\\Users\\cmand\\Lang_Chain_workshop\\Lang_Chain_Workshop\\chroma_db\\chroma.sqlite3 True\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(model=LLM_MODEL, temperature=0.2)\n",
    "embeddings = OllamaEmbeddings(model=EMBED_MODEL)\n",
    "\n",
    "client = chromadb.PersistentClient(path=str(DB_DIR))\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    client=client,                             \n",
    "    collection_name=\"local_research_assistant\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "print(\"LLM and Embeddings ready\")\n",
    "print(\"DB present at:\", DB_DIR / \"chroma.sqlite3\", (DB_DIR / \"chroma.sqlite3\").exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b924cd1",
   "metadata": {},
   "source": [
    "# 5: Cryptography\n",
    "- add more info under the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a707f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more comments\n",
    "# If any PDF is password-protected, add it here:\n",
    "PDF_PASSWORDS: Dict[str, Optional[str]] = {\n",
    "    # \"SomeLockedFile.pdf\": \"your_password_here\",\n",
    "}\n",
    "\n",
    "def load_pdf_pages_robust(pdf_path: Path) -> List:\n",
    "    \"\"\"Load a PDF via PyMuPDF, fall back to PyPDF. Sets absolute 'source' in metadata.\"\"\"\n",
    "    pages: List = []\n",
    "    pwd = PDF_PASSWORDS.get(pdf_path.name)\n",
    "\n",
    "    # 1) PyMuPDF (best text extraction on technical PDFs)\n",
    "    try:\n",
    "        pages = PyMuPDFLoader(str(pdf_path)).load()\n",
    "        for d in pages:\n",
    "            d.metadata[\"source\"] = str(pdf_path.resolve())\n",
    "        if pages:\n",
    "            return pages\n",
    "    except Exception as e:\n",
    "        print(f\"PyMuPDF failed for {pdf_path.name}: {e}\")\n",
    "\n",
    "    # 2) Fallback: PyPDF (needs 'cryptography' for encrypted files)\n",
    "    try:\n",
    "        pages = PyPDFLoader(str(pdf_path), password=pwd).load()\n",
    "        for d in pages:\n",
    "            d.metadata[\"source\"] = str(pdf_path.resolve())\n",
    "        if pages:\n",
    "            return pages\n",
    "    except WrongPasswordError:\n",
    "        print(f\"Skipping encrypted PDF (password needed): {pdf_path.name}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"PyPDF failed for {pdf_path.name}: {e}\")\n",
    "\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f83a60",
   "metadata": {},
   "source": [
    "# 6: Load Documents (PDF's and/or URLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971b016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs found: ['CalculusVolume1-OP.pdf']\n",
      "Loaded 873 pages across 1 PDF(s).\n"
     ]
    }
   ],
   "source": [
    "# Dedupe across *.pdf and *.PDF\n",
    "pdf_paths = sorted({str(p.resolve()) for p in DATA_DIR.glob(\"*.pdf\")} |\n",
    "                    {str(p.resolve()) for p in DATA_DIR.glob(\"*.PDF\")})\n",
    "pdfs = [Path(p) for p in pdf_paths]\n",
    "print(\"PDFs found:\", [p.name for p in pdfs])\n",
    "\n",
    "raw_docs: List = []\n",
    "for p in pdfs:\n",
    "    raw_docs.extend(load_pdf_pages_robust(p))\n",
    "\n",
    "# Optional web pages (if you need them)\n",
    "urls: list[str] = []  # e.g., [\"https://langchain.readthedocs.io/\"]\n",
    "# raw_docs += UnstructuredURLLoader(urls=urls, continue_on_failure=True).load()\n",
    "\n",
    "print(f\"Loaded {len(raw_docs)} pages across {len(pdfs)} PDF(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e2735",
   "metadata": {},
   "source": [
    "# 7: Chunking\n",
    "- Runs over the collection of documents you import.\n",
    "- It breaks it down into chunks up to 1200 Char.\n",
    "- It uses overlap off 200, so as to have cohesion in its chunking.\n",
    "- add_start_index brings in the index metadata so you trace where each chunk came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12297c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 1543 chunks.\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "docs = splitter.split_documents(raw_docs)\n",
    "print(f\"Split into {len(docs)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692240d4",
   "metadata": {},
   "source": [
    "# 8: Vector Store (Create or Reuse; initial add only if empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a763e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed documents (auto-persisted).\n"
     ]
    }
   ],
   "source": [
    "has_index = len(vectorstore.get().get(\"ids\", [])) > 0\n",
    "if (not has_index) and len(docs) > 0:\n",
    "    vectorstore.add_documents(docs)  # auto-persist; no .persist()\n",
    "    print(\"Indexed documents (auto-persisted).\")\n",
    "else:\n",
    "    print(\"Using existing index (or no docs to add).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f70c32",
   "metadata": {},
   "source": [
    "# 9: Folder-wide sync \n",
    "- (add new, remove deleted) \n",
    "- \n",
    "- public API only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8a7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chunk_id(doc):\n",
    "    src  = str(doc.metadata.get(\"source\",\"\"))\n",
    "    page = str(doc.metadata.get(\"page\",\"\"))\n",
    "    head = doc.page_content[:200].encode(\"utf-8\", errors=\"ignore\")\n",
    "    return f\"{src}::p{page}::{hashlib.md5(head).hexdigest()}\"\n",
    "\n",
    "def sync_all_pdfs():\n",
    "    # Current files in folder\n",
    "    current_files = {str(p.resolve()) for p in (list(DATA_DIR.glob(\"*.pdf\")) + list(DATA_DIR.glob(\"*.PDF\")))}\n",
    "\n",
    "    # What's in Chroma now — request a VALID include (ids will still be in the result)\n",
    "    all_data = vectorstore.get(include=[\"metadatas\"])  # no \"ids\" here\n",
    "    existing_ids = set(all_data.get(\"ids\", []))        # ids are still present in the return\n",
    "    metas = all_data.get(\"metadatas\", [])\n",
    "    indexed_sources = {m.get(\"source\") for m in metas if m.get(\"source\")}\n",
    "\n",
    "    # 1) Remove chunks for PDFs that were deleted\n",
    "    removed_sources = {s for s in indexed_sources if s not in current_files}\n",
    "    if removed_sources:\n",
    "        print(f\"Removing chunks for deleted PDFs: {[Path(s).name for s in removed_sources]}\")\n",
    "        for s in removed_sources:\n",
    "            vectorstore.delete(where={\"source\": s})\n",
    "    else:\n",
    "        print(\"No deleted PDFs found.\")\n",
    "\n",
    "    # 2) Add new/changed PDFs\n",
    "    added = 0\n",
    "    for pdf in sorted(current_files):\n",
    "        pages = load_pdf_pages_robust(Path(pdf))\n",
    "        if not pages:\n",
    "            continue\n",
    "        chunks = splitter.split_documents(pages)\n",
    "        ids = [_chunk_id(c) for c in chunks]\n",
    "        new_docs, new_ids = [], []\n",
    "        for d, cid in zip(chunks, ids):\n",
    "            if cid not in existing_ids:\n",
    "                new_docs.append(d); new_ids.append(cid)\n",
    "        if new_docs:\n",
    "            vectorstore.add_documents(new_docs, ids=new_ids)  # auto-persist\n",
    "            existing_ids.update(new_ids)\n",
    "            added += len(new_docs)\n",
    "\n",
    "    print(f\"Sync complete. Added {added} new chunk(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a3e54",
   "metadata": {},
   "source": [
    "# 9b: Optional — Clear and Resync Database\n",
    "- Not needed for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a905f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_chroma_all():\n",
    "    data = vectorstore.get(include=[\"metadatas\"])  # valid include\n",
    "    ids = data.get(\"ids\", [])\n",
    "    if not ids:\n",
    "        print(\"No vectors to delete.\")\n",
    "        return\n",
    "    vectorstore.delete(ids=ids)\n",
    "    print(f\"Cleared {len(ids)} vectors from Chroma.\")\n",
    "\n",
    "#clear_chroma_all()\n",
    "#sync_all_pdfs()  # rebuild from PDFs currently in DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6685c",
   "metadata": {},
   "source": [
    "# 10: Ask helpers\n",
    "- Give more context on the prompt can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c8fb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Add section to be able to change the prompt + needed context variables\n",
    "\n",
    "def ask(question: str) -> str:\n",
    "    rel_docs = retriever.invoke(question)  # new API\n",
    "    context = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"[{Path(d.metadata.get('source','?')).name} p{d.metadata.get('page','?')}] {d.page_content[:1000]}\"\n",
    "        for d in rel_docs\n",
    "    )\n",
    "    prompt = (\n",
    "        \"You are a helpful research assistant. Answer strictly from the context. \"\n",
    "        \"If unsure, say you don't know. Add brief page refs.\\n\\n\"\n",
    "        f\"Q: {question}\\n\\nContext:\\n{context}\\n\\nA:\"\n",
    "    )\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "def ask_fresh(question: str) -> str:\n",
    "    sync_all_pdfs()   # keep index in sync with folder\n",
    "    return ask(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0eca00",
   "metadata": {},
   "source": [
    "# 11: Quick checks for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f861e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs in data/: ['CalculusVolume1-OP.pdf']\n",
      "Indexed chunks: 1543\n"
     ]
    }
   ],
   "source": [
    "print(\"PDFs in data/:\", [p.name for p in DATA_DIR.glob(\"*.pdf\")])\n",
    "print(\"Indexed chunks:\", len((vectorstore.get() or {}).get(\"ids\", [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86fbee",
   "metadata": {},
   "source": [
    "# 12:Question section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "083110dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to explain each method described in CalculusVolume1 like a 5-year-old.\n",
      "\n",
      "Q: What's the first method?\n",
      "\n",
      "A: Okay! The first method is called \"Assessments\". It's like a quiz that helps us learn. In this book, there are lots of questions and problems inside it. We can do them on our own or ask a teacher for help. Some of these questions are even marked with a [T] so we know they're okay to solve by calculator or computer.\n",
      "\n",
      "Page ref: Not available as it's not a real page number.\n",
      "\n",
      "Q: What's the second method?\n",
      "\n",
      "A: The second method is called \"Early or Late Transcendental approaches\". This means that some people learn about calculus in different ways. One way is to start with simple things like exponential and logarithmic functions, and then move on to more complicated stuff. Another way is to focus on how these functions change over time.\n",
      "\n",
      "Page ref: Not available as it's not a real page number.\n",
      "\n",
      "Q: What's the third method?\n",
      "\n",
      "A: The third method is called \"Defining the Derivative\". This means we learn about something called the derivative, which helps us understand how things change. We'll see lots of examples and practice problems to help us get better at this.\n",
      "\n",
      "Page ref: Not available as it's not a real page number.\n",
      "\n",
      "Q: What's the fourth method?\n",
      "\n",
      "A: The fourth method is called \"Checkpoint questions\". These are like practice problems that we do on our own, so we can make sure we understand what we're learning. We'll also get help from teachers if we need it.\n",
      "\n",
      "Page ref: Not available as it's not a real page number.\n",
      "\n",
      "Q: What's the fifth method?\n",
      "\n",
      "A: The fifth method is called \"Practice problems\". These are like puzzles that we do on our own, so we can practice using what we've learned. We'll get help from teachers if we need it too!\n",
      "\n",
      "Page ref: Not available as it's not a real page number.\n",
      "\n",
      "Q: What's the last method?\n",
      "\n",
      "A: The last method is called \"Answer Key\". This is where we find answers to questions and problems that we did in the book. It's like a treasure chest of solutions!\n"
     ]
    }
   ],
   "source": [
    "# Example queries:\n",
    "ans = ask(\"Explain each method that is described in the CalculusVolume1 like a 5 year old.\")\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
