{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e60648e",
   "metadata": {},
   "source": [
    "# Sell the infomation of what we are doing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc344330",
   "metadata": {},
   "source": [
    "# 1: Cell imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae587a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: c:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\.venv\\Scripts\\python.exe\n",
      "cryptography: 46.0.2\n",
      "pypdf: 6.1.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "import hashlib\n",
    "import cryptography\n",
    "import pypdf\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredURLLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "from pypdf.errors import WrongPasswordError\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"cryptography:\", cryptography.__version__)\n",
    "print(\"pypdf:\", pypdf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169576d",
   "metadata": {},
   "source": [
    "# 2: Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3072ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\n",
      "DATA_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\data\n",
      "DB_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\chroma_db\n",
      "DATA_DIR contents: ['CalculusVolume1-OP.pdf']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ROOT_DIR = Path(__file__).parent.resolve()\n",
    "except NameError:\n",
    "    ROOT_DIR = Path(os.getcwd()).resolve()\n",
    "\n",
    "if ROOT_DIR.name.lower() == \"notebooks\":\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "DB_DIR   = ROOT_DIR / \"chroma_db\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT_DIR:\", ROOT_DIR)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DB_DIR:\", DB_DIR)\n",
    "print(\"DATA_DIR contents:\", [p.name for p in DATA_DIR.glob('*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d62a2a",
   "metadata": {},
   "source": [
    "# 3: Ollama Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5315fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL   = \"llama3.2:1b\"          # ollama pull llama3.1\n",
    "EMBED_MODEL = \"nomic-embed-text\"  # ollama pull nomic-embed-text\n",
    "\n",
    "# verify if kaggle or collab will work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a10172",
   "metadata": {},
   "source": [
    "### 3a: Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6677d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\data\n",
      "DB_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DB_DIR:\", DB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c8325",
   "metadata": {},
   "source": [
    "# 4: Sanity Check\n",
    "- This will error if Ollama isn't running or the model isn't pulled yet.\n",
    "- In a terminal (outside Python), run:\n",
    "    - ollama pull llama3.2:1b\n",
    "    - ollama pull nomic-embed-text\n",
    "- Forces Chroma to use the ROOT DB_DIR (outside notebooks) <- hard pins the path\n",
    "- Sanity check: confirm the DB file is in the right place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f5753b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM and Embeddings ready\n",
      "DB present at: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\chroma_db\\chroma.sqlite3 True\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(model=LLM_MODEL, temperature=0.2)\n",
    "embeddings = OllamaEmbeddings(model=EMBED_MODEL)\n",
    "\n",
    "client = chromadb.PersistentClient(path=str(DB_DIR))\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    client=client,                             # <- use client, not persist_directory\n",
    "    collection_name=\"local_research_assistant\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "print(\"LLM and Embeddings ready\")\n",
    "print(\"DB present at:\", DB_DIR / \"chroma.sqlite3\", (DB_DIR / \"chroma.sqlite3\").exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b924cd1",
   "metadata": {},
   "source": [
    "# 5: Cryptography\n",
    "- add more info under the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a707f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more comments\n",
    "# If any PDF is password-protected, add it here:\n",
    "PDF_PASSWORDS: Dict[str, Optional[str]] = {\n",
    "    # \"SomeLockedFile.pdf\": \"your_password_here\",\n",
    "}\n",
    "\n",
    "def load_pdf_pages_robust(pdf_path: Path) -> List:\n",
    "    \"\"\"Load a PDF via PyMuPDF, fall back to PyPDF. Sets absolute 'source' in metadata.\"\"\"\n",
    "    pages: List = []\n",
    "    pwd = PDF_PASSWORDS.get(pdf_path.name)\n",
    "\n",
    "    # 1) PyMuPDF (best text extraction on technical PDFs)\n",
    "    try:\n",
    "        pages = PyMuPDFLoader(str(pdf_path)).load()\n",
    "        for d in pages:\n",
    "            d.metadata[\"source\"] = str(pdf_path.resolve())\n",
    "        if pages:\n",
    "            return pages\n",
    "    except Exception as e:\n",
    "        print(f\"PyMuPDF failed for {pdf_path.name}: {e}\")\n",
    "\n",
    "    # 2) Fallback: PyPDF (needs 'cryptography' for encrypted files)\n",
    "    try:\n",
    "        pages = PyPDFLoader(str(pdf_path), password=pwd).load()\n",
    "        for d in pages:\n",
    "            d.metadata[\"source\"] = str(pdf_path.resolve())\n",
    "        if pages:\n",
    "            return pages\n",
    "    except WrongPasswordError:\n",
    "        print(f\"Skipping encrypted PDF (password needed): {pdf_path.name}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"PyPDF failed for {pdf_path.name}: {e}\")\n",
    "\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f83a60",
   "metadata": {},
   "source": [
    "# 6: Load Documents (PDF's and/or URLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "971b016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs found: ['CalculusVolume1-OP.pdf']\n",
      "Loaded 873 pages across 1 PDF(s).\n"
     ]
    }
   ],
   "source": [
    "# Dedupe across *.pdf and *.PDF\n",
    "pdf_paths = sorted({str(p.resolve()) for p in DATA_DIR.glob(\"*.pdf\")} |\n",
    "                    {str(p.resolve()) for p in DATA_DIR.glob(\"*.PDF\")})\n",
    "pdfs = [Path(p) for p in pdf_paths]\n",
    "print(\"PDFs found:\", [p.name for p in pdfs])\n",
    "\n",
    "raw_docs: List = []\n",
    "for p in pdfs:\n",
    "    raw_docs.extend(load_pdf_pages_robust(p))\n",
    "\n",
    "# Optional web pages (if you need them)\n",
    "urls: list[str] = []  # e.g., [\"https://langchain.readthedocs.io/\"]\n",
    "# raw_docs += UnstructuredURLLoader(urls=urls, continue_on_failure=True).load()\n",
    "\n",
    "print(f\"Loaded {len(raw_docs)} pages across {len(pdfs)} PDF(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e2735",
   "metadata": {},
   "source": [
    "# 7: Chunking\n",
    "- explain how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12297c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 1543 chunks.\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "docs = splitter.split_documents(raw_docs)\n",
    "print(f\"Split into {len(docs)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692240d4",
   "metadata": {},
   "source": [
    "# 8: Vector Store (Create or Reuse; initial add only if empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a763e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing index (or no docs to add).\n"
     ]
    }
   ],
   "source": [
    "has_index = len(vectorstore.get().get(\"ids\", [])) > 0\n",
    "if (not has_index) and len(docs) > 0:\n",
    "    vectorstore.add_documents(docs)  # auto-persist; no .persist()\n",
    "    print(\"Indexed documents (auto-persisted).\")\n",
    "else:\n",
    "    print(\"Using existing index (or no docs to add).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f70c32",
   "metadata": {},
   "source": [
    "# 9: Folder-wide sync \n",
    "- (add new, remove deleted) \n",
    "- \n",
    "— public API only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b8a7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chunk_id(doc):\n",
    "    src  = str(doc.metadata.get(\"source\",\"\"))\n",
    "    page = str(doc.metadata.get(\"page\",\"\"))\n",
    "    head = doc.page_content[:200].encode(\"utf-8\", errors=\"ignore\")\n",
    "    return f\"{src}::p{page}::{hashlib.md5(head).hexdigest()}\"\n",
    "\n",
    "def sync_all_pdfs():\n",
    "    # Current files in folder\n",
    "    current_files = {str(p.resolve()) for p in (list(DATA_DIR.glob(\"*.pdf\")) + list(DATA_DIR.glob(\"*.PDF\")))}\n",
    "\n",
    "    # What's in Chroma now — request a VALID include (ids will still be in the result)\n",
    "    all_data = vectorstore.get(include=[\"metadatas\"])  # ✅ no \"ids\" here\n",
    "    existing_ids = set(all_data.get(\"ids\", []))        # ids are still present in the return\n",
    "    metas = all_data.get(\"metadatas\", [])\n",
    "    indexed_sources = {m.get(\"source\") for m in metas if m.get(\"source\")}\n",
    "\n",
    "    # 1) Remove chunks for PDFs that were deleted\n",
    "    removed_sources = {s for s in indexed_sources if s not in current_files}\n",
    "    if removed_sources:\n",
    "        print(f\"Removing chunks for deleted PDFs: {[Path(s).name for s in removed_sources]}\")\n",
    "        for s in removed_sources:\n",
    "            vectorstore.delete(where={\"source\": s})\n",
    "    else:\n",
    "        print(\"No deleted PDFs found.\")\n",
    "\n",
    "    # 2) Add new/changed PDFs\n",
    "    added = 0\n",
    "    for pdf in sorted(current_files):\n",
    "        pages = load_pdf_pages_robust(Path(pdf))\n",
    "        if not pages:\n",
    "            continue\n",
    "        chunks = splitter.split_documents(pages)\n",
    "        ids = [_chunk_id(c) for c in chunks]\n",
    "        new_docs, new_ids = [], []\n",
    "        for d, cid in zip(chunks, ids):\n",
    "            if cid not in existing_ids:\n",
    "                new_docs.append(d); new_ids.append(cid)\n",
    "        if new_docs:\n",
    "            vectorstore.add_documents(new_docs, ids=new_ids)  # auto-persist\n",
    "            existing_ids.update(new_ids)\n",
    "            added += len(new_docs)\n",
    "\n",
    "    print(f\"Sync complete. Added {added} new chunk(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a3e54",
   "metadata": {},
   "source": [
    "# 9b: Optional — Clear and Resync Database\n",
    "- Not needed for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a905f895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleared 1543 vectors from Chroma.\n",
      "No deleted PDFs found.\n",
      "Sync complete. Added 1543 new chunk(s).\n"
     ]
    }
   ],
   "source": [
    "def clear_chroma_all():\n",
    "    data = vectorstore.get(include=[\"metadatas\"])  # valid include\n",
    "    ids = data.get(\"ids\", [])\n",
    "    if not ids:\n",
    "        print(\"No vectors to delete.\")\n",
    "        return\n",
    "    vectorstore.delete(ids=ids)\n",
    "    print(f\"Cleared {len(ids)} vectors from Chroma.\")\n",
    "\n",
    "clear_chroma_all()\n",
    "sync_all_pdfs()  # rebuild from PDFs currently in DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6685c",
   "metadata": {},
   "source": [
    "# 10: Ask helpers\n",
    "- Give more context on the prompt can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c8fb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Add section to be able to change the prompt + needed context variables\n",
    "\n",
    "def ask(question: str) -> str:\n",
    "    rel_docs = retriever.invoke(question)  # new API\n",
    "    context = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"[{Path(d.metadata.get('source','?')).name} p{d.metadata.get('page','?')}] {d.page_content[:1000]}\"\n",
    "        for d in rel_docs\n",
    "    )\n",
    "    prompt = (\n",
    "        \"You are a helpful research assistant. Answer strictly from the context. \"\n",
    "        \"If unsure, say you don't know. Add brief page refs.\\n\\n\"\n",
    "        f\"Q: {question}\\n\\nContext:\\n{context}\\n\\nA:\"\n",
    "    )\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "def ask_fresh(question: str) -> str:\n",
    "    sync_all_pdfs()   # keep index in sync with folder\n",
    "    return ask(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0eca00",
   "metadata": {},
   "source": [
    "# 11: Quick checks for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f861e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs in data/: ['CalculusVolume1-OP.pdf']\n",
      "Indexed chunks: 1543\n"
     ]
    }
   ],
   "source": [
    "print(\"PDFs in data/:\", [p.name for p in DATA_DIR.glob(\"*.pdf\")])\n",
    "print(\"Indexed chunks:\", len((vectorstore.get() or {}).get(\"ids\", [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86fbee",
   "metadata": {},
   "source": [
    "# 12:Question section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083110dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to explain each method in CalculusVolume1 like a 5-year-old.\n",
      "\n",
      "**Defining the Derivative**\n",
      "\n",
      "Imagine you're playing with a toy car on a track. You want to know how fast it's moving at any given moment. One way to do this is to look at how far it has traveled so far and divide that by the time it took to get there. That's kind of like what the derivative does - it helps us figure out how fast something (like a function) is changing at any given point.\n",
      "\n",
      "Think of it like this: Imagine you have a toy box with some toys inside, and you want to know how fast they're moving around in the box. You can measure how many toys are in the box at one moment, and then divide that by how long it's been since you measured them. That gives you an idea of how fast the toys are moving.\n",
      "\n",
      "**Calculating the Slope of a Tangent Line**\n",
      "\n",
      "Now, let's say you have a toy car on the track, and you want to know its speed at any given moment. You can use the derivative to figure out that speed. The derivative tells you the rate of change of the speed (how fast it's changing) at any given point.\n",
      "\n",
      "Think of it like this: Imagine you're standing next to the toy car on the track, and you want to know how fast it's moving. You can measure its speed by looking at how far it has traveled in a certain amount of time. The derivative is like a special tool that helps us figure out how fast that speed is changing.\n",
      "\n",
      "**Identifying the Derivative as the Limit of a Difference Quotient**\n",
      "\n",
      "The derivative is also equal to the limit of a difference quotient. A difference quotient is a way of finding the rate of change by looking at how things change over a small amount of time. The derivative is like a special tool that helps us figure out what that rate of change is.\n",
      "\n",
      "Think of it like this: Imagine you're standing next to the toy car on the track, and you want to know its speed at any given moment. You can use a difference quotient to find the rate of change by looking at how far it has traveled in a small amount of time. The derivative is like a special tool that helps us figure out what that rate of change is.\n",
      "\n",
      "**Calculating the Derivative of a Given Function**\n",
      "\n",
      "The derivative is also used to calculate the slope of a tangent line to a curve. Imagine you have a toy car on the track, and you want to know its speed at any given moment. You can use the derivative to figure out how fast it's moving.\n",
      "\n",
      "Think of it like this: Imagine you're standing next to the toy car on the track, and you want to know its speed at any given moment. You can measure its speed by looking at how far it has traveled in a certain amount of time. The derivative is like a special tool that helps us figure out what that speed is.\n",
      "\n",
      "**Describing the Velocity as a Rate of Change**\n",
      "\n",
      "Velocity is also equal to the rate of change of an object's position over time. Think of it like this: Imagine you're standing next to the toy car on the track, and you want to know how fast it's moving at any given moment. You can use velocity to figure out that speed.\n",
      "\n",
      "**Explaining the Difference between Average Velocity and Instantaneous Velocity**\n",
      "\n",
      "Average velocity is like a long-term average speed of an object. It's like taking a bunch of measurements over time and then averaging them together. Instantaneous velocity, on the other hand, is like a short-term speed at a specific moment in time. It's like looking at one measurement right now.\n",
      "\n",
      "**Estimating the Derivative from a Table of Values**\n",
      "\n",
      "The derivative can also be estimated by looking at a table of values. Think of it like this: Imagine you have a toy car on the track, and you want to know its speed at any given moment. You can use a table of values to estimate how fast it's moving.\n",
      "\n",
      "**Calculus Volume 1 is designed to accommodate both Early and Late Transcendental approaches to calculus**\n",
      "\n",
      "Early transcendental approaches focus on basic concepts like functions, graphs, and limits, while late transcendental approaches explore more advanced topics like derivatives, integrals, and multivariable calculus.\n"
     ]
    }
   ],
   "source": [
    "# Example queries:\n",
    "ans = ask(\"Explain each method that is described in the CalculusVolume1 like a 5 year old.\")\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
