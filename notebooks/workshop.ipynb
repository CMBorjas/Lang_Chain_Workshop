{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c969e783",
   "metadata": {},
   "source": [
    "# LangChain Workshop: Building Intelligent Applications with Local LLMs\n",
    "\n",
    "Welcome to the **LangChain Workshop** — an interactive session designed to introduce you to one of the most powerful frameworks for building **AI-driven applications**.  \n",
    "In this workshop, you’ll learn how to connect **Large Language Models (LLMs)** with your own data, enabling intelligent systems that can **reason, retrieve, and respond** using real-world information.\n",
    "\n",
    "---\n",
    "\n",
    "## What is LangChain?\n",
    "\n",
    "**LangChain** is an open-source framework that simplifies working with LLMs like GPT or LLaMA by giving them **memory**, **tools**, and **data access**.  \n",
    "Instead of just chatting with a model, LangChain helps you **build agents and applications** that can:\n",
    "- Read and summarize documents  \n",
    "- Answer questions from your own data  \n",
    "- Chain multiple reasoning steps together  \n",
    "- Connect to APIs, databases, and local files  \n",
    "\n",
    "Think of LangChain as the “glue” between your AI model and the information or actions it needs to perform.\n",
    "\n",
    "---\n",
    "\n",
    "## Why Learn LangChain?\n",
    "\n",
    "Learning LangChain unlocks your ability to **build real-world AI tools** that go beyond simple prompts.  \n",
    "By the end of this workshop, you’ll understand how to:\n",
    "\n",
    "- Create **Retrieval-Augmented Generation (RAG)** pipelines  \n",
    "- Store and search data in **vector databases** (like Chroma or Qdrant)  \n",
    "- Integrate **local LLMs** (e.g., Ollama + Llama 3)  \n",
    "- Run your own **AI-powered assistant** on your computer or server  \n",
    "\n",
    "LangChain bridges the gap between **AI theory and practical engineering**, giving you hands-on experience with the same technologies powering next-generation AI products.\n",
    "\n",
    "---\n",
    "\n",
    "## What You’ll Build\n",
    "\n",
    "In this session, you’ll:\n",
    "1. Set up a local LangChain environment  \n",
    "2. Ingest and index your own text data  \n",
    "3. Create a simple **local research assistant** that can answer questions about your documents  \n",
    "4. Run it fully **offline** using a local LLM  \n",
    "\n",
    "By the end, you’ll have a working foundation for your own **AI apps, research tools, and automation projects**.\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Basic familiarity with **Python**  \n",
    "- Installed **Jupyter Notebook**    \n",
    "\n",
    "---\n",
    "\n",
    "## Let’s Begin\n",
    "\n",
    "> “LangChain turns your data into dialogue and your ideas into intelligent systems.”  \n",
    "Let’s dive in and explore how you can build your own AI assistant — from scratch to smart — in one workshop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc344330",
   "metadata": {},
   "source": [
    "# 1: Cell imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae587a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: c:\\Users\\cmand\\AppData\\Local\\Programs\\Python\\Python312\\python.exe\n",
      "cryptography: 43.0.3\n",
      "pypdf: 5.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "import hashlib\n",
    "import cryptography\n",
    "import pypdf\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Dict\n",
    "from langchain_community.document_loaders import PyPDFLoader, UnstructuredURLLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaLLM, OllamaEmbeddings\n",
    "from pypdf.errors import WrongPasswordError\n",
    "\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"cryptography:\", cryptography.__version__)\n",
    "print(\"pypdf:\", pypdf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169576d",
   "metadata": {},
   "source": [
    "# 2: Data Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3072ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\n",
      "DATA_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\data\n",
      "DB_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\chroma_db\n",
      "DATA_DIR contents: ['CalculusVolume1-OP.pdf']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ROOT_DIR = Path(__file__).parent.resolve()\n",
    "except NameError:\n",
    "    ROOT_DIR = Path(os.getcwd()).resolve()\n",
    "\n",
    "if ROOT_DIR.name.lower() == \"notebooks\":\n",
    "    ROOT_DIR = ROOT_DIR.parent\n",
    "\n",
    "DATA_DIR = ROOT_DIR / \"data\"\n",
    "DB_DIR   = ROOT_DIR / \"chroma_db\"\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"ROOT_DIR:\", ROOT_DIR)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DB_DIR:\", DB_DIR)\n",
    "print(\"DATA_DIR contents:\", [p.name for p in DATA_DIR.glob('*')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d62a2a",
   "metadata": {},
   "source": [
    "# 3: Ollama Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e5315fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL   = \"llama3.2:1b\"          # ollama pull llama3.1\n",
    "EMBED_MODEL = \"nomic-embed-text\"  # ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a10172",
   "metadata": {},
   "source": [
    "### 3a: Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6677d326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\data\n",
      "DB_DIR: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"DB_DIR:\", DB_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c8325",
   "metadata": {},
   "source": [
    "# 4: Sanity Check\n",
    "- This will error if Ollama isn't running or the model isn't pulled yet.\n",
    "- In a terminal (outside Python), run:\n",
    "    - ollama pull llama3.2:1b\n",
    "    - ollama pull nomic-embed-text\n",
    "- Forces Chroma to use the ROOT DB_DIR (outside notebooks) <- hard pins the path\n",
    "- We use client, to point to our database.\n",
    "- Sanity check: confirm the DB file is in the right folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f5753b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM and Embeddings ready\n",
      "DB present at: C:\\Users\\Christian\\Desktop\\LangChain-Local-RA\\chroma_db\\chroma.sqlite3 True\n"
     ]
    }
   ],
   "source": [
    "llm = OllamaLLM(model=LLM_MODEL, temperature=0.2)\n",
    "embeddings = OllamaEmbeddings(model=EMBED_MODEL)\n",
    "\n",
    "client = chromadb.PersistentClient(path=str(DB_DIR))\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    client=client,                             \n",
    "    collection_name=\"local_research_assistant\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "\n",
    "print(\"LLM and Embeddings ready\")\n",
    "print(\"DB present at:\", DB_DIR / \"chroma.sqlite3\", (DB_DIR / \"chroma.sqlite3\").exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b924cd1",
   "metadata": {},
   "source": [
    "# 5: Cryptography\n",
    "- add more info under the titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58a707f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more comments\n",
    "# If any PDF is password-protected, add it here:\n",
    "PDF_PASSWORDS: Dict[str, Optional[str]] = {\n",
    "    # \"SomeLockedFile.pdf\": \"your_password_here\",\n",
    "}\n",
    "\n",
    "def load_pdf_pages_robust(pdf_path: Path) -> List:\n",
    "    \"\"\"Load a PDF via PyMuPDF, fall back to PyPDF. Sets absolute 'source' in metadata.\"\"\"\n",
    "    pages: List = []\n",
    "    pwd = PDF_PASSWORDS.get(pdf_path.name)\n",
    "\n",
    "    # 1) PyMuPDF (best text extraction on technical PDFs)\n",
    "    try:\n",
    "        pages = PyMuPDFLoader(str(pdf_path)).load()\n",
    "        for d in pages:\n",
    "            d.metadata[\"source\"] = str(pdf_path.resolve())\n",
    "        if pages:\n",
    "            return pages\n",
    "    except Exception as e:\n",
    "        print(f\"PyMuPDF failed for {pdf_path.name}: {e}\")\n",
    "\n",
    "    # 2) Fallback: PyPDF (needs 'cryptography' for encrypted files)\n",
    "    try:\n",
    "        pages = PyPDFLoader(str(pdf_path), password=pwd).load()\n",
    "        for d in pages:\n",
    "            d.metadata[\"source\"] = str(pdf_path.resolve())\n",
    "        if pages:\n",
    "            return pages\n",
    "    except WrongPasswordError:\n",
    "        print(f\"Skipping encrypted PDF (password needed): {pdf_path.name}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"PyPDF failed for {pdf_path.name}: {e}\")\n",
    "\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f83a60",
   "metadata": {},
   "source": [
    "# 6: Load Documents (PDF's and/or URLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "971b016d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs found: ['CalculusVolume1-OP.pdf']\n",
      "Loaded 873 pages across 1 PDF(s).\n"
     ]
    }
   ],
   "source": [
    "# Dedupe across *.pdf and *.PDF\n",
    "pdf_paths = sorted({str(p.resolve()) for p in DATA_DIR.glob(\"*.pdf\")} |\n",
    "                    {str(p.resolve()) for p in DATA_DIR.glob(\"*.PDF\")})\n",
    "pdfs = [Path(p) for p in pdf_paths]\n",
    "print(\"PDFs found:\", [p.name for p in pdfs])\n",
    "\n",
    "raw_docs: List = []\n",
    "for p in pdfs:\n",
    "    raw_docs.extend(load_pdf_pages_robust(p))\n",
    "\n",
    "# Optional web pages (if you need them)\n",
    "urls: list[str] = []  # e.g., [\"https://langchain.readthedocs.io/\"]\n",
    "# raw_docs += UnstructuredURLLoader(urls=urls, continue_on_failure=True).load()\n",
    "\n",
    "print(f\"Loaded {len(raw_docs)} pages across {len(pdfs)} PDF(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e2735",
   "metadata": {},
   "source": [
    "# 7: Chunking\n",
    "- Runs over the collection of documents you import.\n",
    "- It breaks it down into chunks up to 1200 Char.\n",
    "- It uses overlap off 200, so as to have cohesion in its chunking.\n",
    "- add_start_index brings in the index metadata so you trace where each chunk came from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12297c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 1543 chunks.\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    add_start_index=True,\n",
    ")\n",
    "docs = splitter.split_documents(raw_docs)\n",
    "print(f\"Split into {len(docs)} chunks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692240d4",
   "metadata": {},
   "source": [
    "# 8: Vector Store (Create or Reuse; initial add only if empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a763e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing index (or no docs to add).\n"
     ]
    }
   ],
   "source": [
    "has_index = len(vectorstore.get().get(\"ids\", [])) > 0\n",
    "if (not has_index) and len(docs) > 0:\n",
    "    vectorstore.add_documents(docs)  # auto-persist; no .persist()\n",
    "    print(\"Indexed documents (auto-persisted).\")\n",
    "else:\n",
    "    print(\"Using existing index (or no docs to add).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f70c32",
   "metadata": {},
   "source": [
    "# 9: Folder-wide sync \n",
    "- (add new, remove deleted) \n",
    "- \n",
    "- public API only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b8a7938",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _chunk_id(doc):\n",
    "    src  = str(doc.metadata.get(\"source\",\"\"))\n",
    "    page = str(doc.metadata.get(\"page\",\"\"))\n",
    "    head = doc.page_content[:200].encode(\"utf-8\", errors=\"ignore\")\n",
    "    return f\"{src}::p{page}::{hashlib.md5(head).hexdigest()}\"\n",
    "\n",
    "def sync_all_pdfs():\n",
    "    # Current files in folder\n",
    "    current_files = {str(p.resolve()) for p in (list(DATA_DIR.glob(\"*.pdf\")) + list(DATA_DIR.glob(\"*.PDF\")))}\n",
    "\n",
    "    # What's in Chroma now — request a VALID include (ids will still be in the result)\n",
    "    all_data = vectorstore.get(include=[\"metadatas\"])  # no \"ids\" here\n",
    "    existing_ids = set(all_data.get(\"ids\", []))        # ids are still present in the return\n",
    "    metas = all_data.get(\"metadatas\", [])\n",
    "    indexed_sources = {m.get(\"source\") for m in metas if m.get(\"source\")}\n",
    "\n",
    "    # 1) Remove chunks for PDFs that were deleted\n",
    "    removed_sources = {s for s in indexed_sources if s not in current_files}\n",
    "    if removed_sources:\n",
    "        print(f\"Removing chunks for deleted PDFs: {[Path(s).name for s in removed_sources]}\")\n",
    "        for s in removed_sources:\n",
    "            vectorstore.delete(where={\"source\": s})\n",
    "    else:\n",
    "        print(\"No deleted PDFs found.\")\n",
    "\n",
    "    # 2) Add new/changed PDFs\n",
    "    added = 0\n",
    "    for pdf in sorted(current_files):\n",
    "        pages = load_pdf_pages_robust(Path(pdf))\n",
    "        if not pages:\n",
    "            continue\n",
    "        chunks = splitter.split_documents(pages)\n",
    "        ids = [_chunk_id(c) for c in chunks]\n",
    "        new_docs, new_ids = [], []\n",
    "        for d, cid in zip(chunks, ids):\n",
    "            if cid not in existing_ids:\n",
    "                new_docs.append(d); new_ids.append(cid)\n",
    "        if new_docs:\n",
    "            vectorstore.add_documents(new_docs, ids=new_ids)  # auto-persist\n",
    "            existing_ids.update(new_ids)\n",
    "            added += len(new_docs)\n",
    "\n",
    "    print(f\"Sync complete. Added {added} new chunk(s).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a3e54",
   "metadata": {},
   "source": [
    "# 9b: Optional — Clear and Resync Database\n",
    "- Not needed for presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a905f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_chroma_all():\n",
    "    data = vectorstore.get(include=[\"metadatas\"])  # valid include\n",
    "    ids = data.get(\"ids\", [])\n",
    "    if not ids:\n",
    "        print(\"No vectors to delete.\")\n",
    "        return\n",
    "    vectorstore.delete(ids=ids)\n",
    "    print(f\"Cleared {len(ids)} vectors from Chroma.\")\n",
    "\n",
    "#clear_chroma_all()\n",
    "#sync_all_pdfs()  # rebuild from PDFs currently in DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd6685c",
   "metadata": {},
   "source": [
    "# 10: Ask helpers\n",
    "- Give more context on the prompt can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c8fb98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "\n",
    "# Add section to be able to change the prompt + needed context variables\n",
    "\n",
    "def ask(question: str) -> str:\n",
    "    rel_docs = retriever.invoke(question)  # new API\n",
    "    context = \"\\n\\n---\\n\\n\".join(\n",
    "        f\"[{Path(d.metadata.get('source','?')).name} p{d.metadata.get('page','?')}] {d.page_content[:1000]}\"\n",
    "        for d in rel_docs\n",
    "    )\n",
    "    prompt = (\n",
    "        \"You are a helpful research assistant. Answer strictly from the context. \"\n",
    "        \"If unsure, say you don't know. Add brief page refs.\\n\\n\"\n",
    "        f\"Q: {question}\\n\\nContext:\\n{context}\\n\\nA:\"\n",
    "    )\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "def ask_fresh(question: str) -> str:\n",
    "    sync_all_pdfs()   # keep index in sync with folder\n",
    "    return ask(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0eca00",
   "metadata": {},
   "source": [
    "# 11: Quick checks for new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f861e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDFs in data/: ['CalculusVolume1-OP.pdf']\n",
      "Indexed chunks: 1543\n"
     ]
    }
   ],
   "source": [
    "print(\"PDFs in data/:\", [p.name for p in DATA_DIR.glob(\"*.pdf\")])\n",
    "print(\"Indexed chunks:\", len((vectorstore.get() or {}).get(\"ids\", [])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce86fbee",
   "metadata": {},
   "source": [
    "# 12:Question section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "083110dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd be happy to explain each method described in CalculusVolume1 like a 5-year-old.\n",
      "\n",
      "**Defining the Derivative**\n",
      "\n",
      "Imagine you're playing with a toy car, and you want to know how fast it's moving. You can measure how far it has traveled (that's like finding the distance) or how quickly it's moving (that's like finding the speed). The derivative is like a special number that tells us how fast something is changing at any given moment.\n",
      "\n",
      "Think of it like this: Imagine you have a toy box with some toys inside. If you open the box and find 5 toys, that means the number of toys in the box has changed (it's increased by 5). The derivative would be like finding out how many toys are in the box right now, which is 5.\n",
      "\n",
      "**Calculating the Slope of a Tangent Line**\n",
      "\n",
      "Imagine you're drawing a line on a piece of paper. You want to know how steep that line is. To do this, you can use something called a \"slope\" (it's like a secret code for measuring steepness). The slope is like a number that tells us how fast the line is rising or falling.\n",
      "\n",
      "Think of it like this: Imagine you're playing with a toy car on a hill. If the hill is really steep, the slope will be high (like 10!). If the hill is not so steep, the slope will be low (like 2%).\n",
      "\n",
      "**Identifying the Derivative as the Limit of a Difference Quotient**\n",
      "\n",
      "Imagine you have two toy cars that are moving at different speeds. You want to know how fast one car is going compared to the other. To do this, you can use something called a \"difference quotient\" (it's like a secret code for finding the difference between two numbers). The derivative is like the limit of this difference quotient.\n",
      "\n",
      "Think of it like this: Imagine you have two toy cars that are moving at different speeds. If one car is going really fast and the other car is slow, the difference quotient will be high (like 10!). If both cars are moving at the same speed, the difference quotient will be low (like 2%).\n",
      "\n",
      "**Calculating the Derivative of a Given Function**\n",
      "\n",
      "Imagine you have a toy box with some toys inside. You want to know how many toys are in the box right now, which is like finding the derivative. To do this, you can use something called \"differentiation\" (it's like solving a secret code for finding the number of toys).\n",
      "\n",
      "Think of it like this: Imagine you have a toy car that is moving on a track. You want to know how fast the car is going at any given moment. To find out, you need to look at all the tiny changes in the track (like the slope of the track) and add them up.\n",
      "\n",
      "**Describing the Velocity as a Rate of Change**\n",
      "\n",
      "Imagine you're playing with a toy car on a hill. You want to know how fast the car is going down the hill. To do this, you can use something called \"velocity\" (it's like measuring speed). The velocity is like a number that tells us how fast the car is moving.\n",
      "\n",
      "Think of it like this: Imagine you're playing with a toy car on a hill. If the hill is steep, the velocity will be high (like 10!). If the hill is not so steep, the velocity will be low (like 2%).\n",
      "\n",
      "**Explaining the Difference between Average Velocity and Instantaneous Velocity**\n",
      "\n",
      "Imagine you're playing with a toy car on a track. You want to know how fast the car is going at any given moment. There are two ways to do this: one way is to look at all the tiny changes in the track (like the slope of the track) over a long time, and another way is to look at just one tiny change (like the slope of the track right now).\n",
      "\n",
      "Think of it like this: Imagine you're playing with a toy car on a track. If you look at all the tiny changes in the track over a long time, you'll see that the velocity is always changing (it's like the slope of the track). But if you just look at one tiny change right now, you'll see that the velocity is really high (like 10!).\n",
      "\n",
      "**Estimating the Derivative from a Table of Values**\n",
      "\n",
      "Imagine you have a toy box with some toys inside. You want to know how many toys are in the box right now, which is like finding the derivative. To do this, you can use something called \"estimation\" (it's like guessing). You can look at all the tiny changes in the table of values and make an educated guess about the derivative.\n",
      "\n",
      "Think of it like this: Imagine you have a toy car on a track. If you look at all the tiny changes in the track over time, you'll see that the velocity is always changing (it's like the slope of the track). But if you just look at one tiny change right now, you might guess that the velocity is really high (like 10!).\n"
     ]
    }
   ],
   "source": [
    "# Example queries:\n",
    "ans = ask(\"Explain each method that is described in the CalculusVolume1 like a 5 year old.\")\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
